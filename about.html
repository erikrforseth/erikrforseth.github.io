---
layout: default
title: About this model.
---
A large number of people have developed models for predicting the outcomes of college basketball games. For those that have made their picks publicly available, <a href="http://www.thepredictiontracker.com/basketball.php">ThePredictionTracker</a> does a great service by tracking the live performance of each model over the course of the season. Unfortunately, it's difficult to do a direct comparison of models using the summary page on the Tracker. For one thing, each model has predicted a different subset of games (in many cases this is accidental -- schedules get modified and web scrapers don't pick up the changes -- but some models don't start making picks altogether until weeks or months into the season). Further, there are a few misprinted lines in the Tracker data. For example, the Tracker shows an opening line of -22 and a closing line of +64.5 for UCLA vs. Presbyterian on 11/19/2019 (the line closed at -23 or -23.5 depending on the book). 
<br><br>
Throughout the 2018-19 season, I'll try to update this page with some further analysis of the Tracker data. For what follows, I chose a subset of models which have made picks since the very beginning of the season, and I threw out games for which any of those models did not make a pick. In a (somewhat lazy) attempt to address misprinted lines, I filtered out any games for which the opening and closing lines differed by more than 5 points (it's very rare that this really happens). 
<br><br>
Results shown are as of 2019-01-29 for a set of 3138 games: 
<br>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: center;">
      <th>Mean Squared Error (MSE)</th>
      <th>Model</th>
    </tr>
  </thead>
  <tbody>
    <tr align="center">
      <td>124.619</td>
      <td>Line</td>
    </tr>
    <tr align="center">
      <td>126.145</td>
      <td>Opening Line</td>
    </tr>
    <tr align="center">
      <td>126.278</td>
      <td>Erik Forseth</td>
    </tr>
    <tr align="center">
      <td>127.049</td>
      <td>TeamRankings</td>
    </tr>
    <tr align="center">
      <td>129.068</td>
      <td>Dokter Entropy</td>
    </tr>
    <tr align="center">
      <td>131.316</td>
      <td>ESPN BPI</td>
    </tr>
    <tr align="center">
      <td>131.772</td>
      <td>Sagarin Rating</td>
    </tr>
    <tr align="center">
      <td>132.071</td>
      <td>Sagarin Predictor</td>
    </tr>
    <tr align="center">
      <td>132.773</td>
      <td>Sagarin Golden Mean</td>
    </tr>
    <tr align="center">
      <td>133.752</td>
      <td>Kenneth Massey</td>
    </tr>
    <tr align="center">
      <td>136.850</td>
      <td>DRatings.com</td>
    </tr>
    <tr align="center">
      <td>137.728</td>
      <td>Sonny Moore</td>
    </tr>
    <tr align="center">
      <td>143.317</td>
      <td>StatFox</td>
    </tr>
    <tr align="center">
      <td>144.851</td>
      <td>ComPughter Ratings</td>
    </tr>
    <tr align="center">
      <td>149.110</td>
      <td>Sagarin Recent</td>
    </tr>
  </tbody>
</table>
<br>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: center;">
      <th>Accuracy</th>
      <th>Model</th>
    </tr>
  </thead>
  <tbody>
    <tr align="center">
      <td>0.757</td>
      <td>Erik Forseth</td>
    </tr>
    <tr align="center">
      <td>0.756</td>
      <td>Opening Line</td>
    </tr>
    <tr align="center">
      <td>0.755</td>
      <td>Line</td>
    </tr>
    <tr align="center">
      <td>0.752</td>
      <td>ESPN BPI</td>
    </tr>
    <tr align="center">
      <td>0.752</td>
      <td>TeamRankings</td>
    </tr>
    <tr align="center">
      <td>0.750</td>
      <td>Sagarin Rating</td>
    </tr>
    <tr align="center">
      <td>0.750</td>
      <td>Sagarin Predictor</td>
    </tr>
    <tr align="center">
      <td>0.747</td>
      <td>Sagarin Golden Mean</td>
    </tr>
    <tr align="center">
      <td>0.744</td>
      <td>Kenneth Massey</td>
    </tr>
    <tr align="center">
      <td>0.744</td>
      <td>Dokter Entropy</td>
    </tr>
    <tr align="center">
      <td>0.743</td>
      <td>Sonny Moore</td>
    </tr>
    <tr align="center">
      <td>0.742</td>
      <td>DRatings.com</td>
    </tr>
    <tr align="center">
      <td>0.735</td>
      <td>StatFox</td>
    </tr>
    <tr align="center">
      <td>0.735</td>
      <td>ComPughter Ratings</td>
    </tr>
    <tr align="center">
      <td>0.730</td>
      <td>Sagarin Recent</td>
    </tr>
  </tbody>
</table>
<br><br>
Clearly the line is the best statistical predictor of the outcome. Nevertheless, we can ask how each model would have done against the spread, shown below: 
<br>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: center;">
      <th>% Against the Spread</th>
      <th>Model</th>
    </tr>
  </thead>
  <tbody>
    <tr align="center">
      <td>0.517</td>
      <td>ESPN BPI</td>
    </tr>
    <tr align="center">
      <td>0.508</td>
      <td>Sagarin Golden Mean</td>
    </tr>
    <tr align="center">
      <td>0.506</td>
      <td>Sonny Moore</td>
    </tr>
    <tr align="center">
      <td>0.504</td>
      <td>Sagarin Rating</td>
    </tr>
    <tr align="center">
      <td>0.504</td>
      <td>Dokter Entropy</td>
    </tr>
    <tr align="center">
      <td>0.504</td>
      <td>Sagarin Predictor</td>
    </tr>
    <tr align="center">
      <td>0.500</td>
      <td>Erik Forseth</td>
    </tr>
    <tr align="center">
      <td>0.497</td>
      <td>DRatings.com</td>
    </tr>
    <tr align="center">
      <td>0.496</td>
      <td>Kenneth Massey</td>
    </tr>
    <tr align="center">
      <td>0.496</td>
      <td>TeamRankings</td>
    </tr>
    <tr align="center">
      <td>0.493</td>
      <td>Opening Line</td>
    </tr>
    <tr align="center">
      <td>0.493</td>
      <td>StatFox</td>
    </tr>
    <tr align="center">
      <td>0.489</td>
      <td>Sagarin Recent</td>
    </tr>
    <tr align="center">
      <td>0.480</td>
      <td>ComPughter Ratings</td>
    </tr>
  </tbody>
</table>
<br><br>
 Although no individual model predicts the point spread as well as the line, we might ask whether any linear combination of models can do so. Let's regress the observed margins of victory onto the predictions of each model, but constrain the regression to have nonnegative coefficients. Subject to the nonnegativity constraint, this would give the optimal (backward-looking) mixture of predictors. We find: 
<br>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: center;">
      <th>Coefficient</th>
      <th>Model</th>
    </tr>
  </thead>
  <tbody>
    <tr align="center">
      <td>0.489</td>
      <td>Erik Forseth</td>
    </tr>
    <tr align="center">
      <td>0.246</td>
      <td>ESPN BPI</td>
    </tr>
    <tr align="center">
      <td>0.210</td>
      <td>Dokter Entropy</td>
    </tr>
    <tr align="center">
      <td>0.040</td>
      <td>Sonny Moore</td>
    </tr>
    <tr align="center">
      <td>0.027</td>
      <td>Sagarin Predictor</td>
    </tr>
    <tr align="center">
      <td>0.000</td>
      <td>Kenneth Massey</td>
    </tr>
    <tr align="center">
      <td>0.000</td>
      <td>Sagarin Rating</td>
    </tr>
    <tr align="center">
      <td>0.000</td>
      <td>TeamRankings</td>
    </tr>
    <tr align="center">
      <td>0.000</td>
      <td>StatFox</td>
    </tr>
    <tr align="center">
      <td>0.000</td>
      <td>Sagarin Recent</td>
    </tr>
    <tr align="center">
      <td>0.000</td>
      <td>Sagarin Golden Mean</td>
    </tr>
    <tr align="center">
      <td>0.000</td>
      <td>DRatings.com</td>
    </tr>
    <tr align="center">
      <td>0.000</td>
      <td>ComPughter Ratings</td>
    </tr>
  </tbody>
</table> 
<br>
The MSE of this hypothetical predictor would be 125.062. Note that this is optimistic, since in addition to being backward-looking, we both fit the model and then computed the MSE using the full dataset. 
<br><br>
Out of curiosity, what if we included the line itself in the above regression? Can any of our models add value when combined with the line?<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: center;">
      <th>Coefficient</th>
      <th>Model</th>
    </tr>
  </thead>
  <tbody>
    <tr align="center">
      <td>0.619</td>
      <td>Line</td>
    </tr>
    <tr align="center">
      <td>0.205</td>
      <td>Erik Forseth</td>
    </tr>
    <tr align="center">
      <td>0.146</td>
      <td>ESPN BPI</td>
    </tr>
    <tr align="center">
      <td>0.049</td>
      <td>Dokter Entropy</td>
    </tr>
    <tr align="center">
      <td>0.001</td>
      <td>Sonny Moore</td>
    </tr>
    <tr align="center">
      <td>0.000</td>
      <td>Opening Line</td>
    </tr>
    <tr align="center">
      <td>0.000</td>
      <td>Kenneth Massey</td>
    </tr>
    <tr align="center">
      <td>0.000</td>
      <td>Sagarin Rating</td>
    </tr>
    <tr align="center">
      <td>0.000</td>
      <td>TeamRankings</td>
    </tr>
    <tr align="center">
      <td>0.000</td>
      <td>StatFox</td>
    </tr>
    <tr align="center">
      <td>0.000</td>
      <td>Sagarin Recent</td>
    </tr>
    <tr align="center">
      <td>0.000</td>
      <td>Sagarin Predictor</td>
    </tr>
    <tr align="center">
      <td>0.000</td>
      <td>Sagarin Golden Mean</td>
    </tr>
    <tr align="center">
      <td>0.000</td>
      <td>DRatings.com</td>
    </tr>
    <tr align="center">
      <td>0.000</td>
      <td>ComPughter Ratings</td>
    </tr>
  </tbody>
</table> 
<br>
Interestingly, it seems that a couple of the models do perhaps capture something the line does not. The hypothetical MSE of this mixture would be 124.101. 
<br><br>
At some point I will make my analysis available as a Jupyter notebook.
