---
layout: default
title: About this model.
---
A large number of people have developed models for predicting the outcomes of college basketball games. For those that have made their picks publicly available, <a href="http://www.thepredictiontracker.com/basketball.php">ThePredictionTracker</a> does a great service by tracking the live performance of each model over the course of the season. Unfortunately, it's difficult to do a direct comparison of models using the summary page on the Tracker, in part because each model has predicted a different subset of games (in many cases this is accidental -- schedules get modified and web scrapers don't pick up the changes -- but some models don't start making picks altogether until weeks or months into the season). Throughout the season, I'll try to update this page with some further analysis of the Tracker data. For what follows, I chose a subset of models which have made picks since the very beginning of the season, and I threw out games for which any of those models did not make a pick. In a (somewhat lazy) attempt to address misprinted lines, I filtered out any games for which the opening and closing lines differed by more than 5 points (it's very rare that this really happens). 
<br><br>
Results are shown as of 2019-12-20 for a set of 1018 games: 
<br>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: center;">
      <th>Model</th>
      <th>Mean Squared Error (MSE)</th>
    </tr>
  </thead>
  <tbody>
    <tr align="center">
      <td>Opening Line</td>
      <td>143.991</td>
    </tr>
    <tr align="center">
      <td>Line</td>
      <td>144.648</td>
    </tr>
    <tr align="center">
      <td>Erik Forseth</td>
      <td>145.134</td>
    </tr>
    <tr align="center">
      <td>TeamRankings</td>
      <td>146.854</td>
    </tr>
    <tr align="center">
      <td>ESPN BPI</td>
      <td>148.231</td>
    </tr>
    <tr align="center">
      <td>Sagarin Predictor</td>
      <td>149.390</td>
    </tr>
    <tr align="center">
      <td>Dokter Entropy</td>
      <td>149.771</td>
    </tr>
    <tr align="center">
      <td>Sagarin Golden Mean</td>
      <td>151.387</td>
    </tr>
    <tr align="center">
      <td>Sagarin Rating</td>
      <td>151.717</td>
    </tr>
    <tr align="center">
      <td>StatFox</td>
      <td>159.446</td>
    </tr>
    <tr align="center">
      <td>Sonny Moore</td>
      <td>161.483</td>
    </tr>
    <tr align="center">
      <td>Kenneth Massey</td>
      <td>162.170</td>
    </tr>
    <tr align="center">
      <td>DRatings.com</td>
      <td>162.308</td>
    </tr>
    <tr align="center">
      <td>Sagarin Recent</td>
      <td>163.268</td>
    </tr>
    <tr align="center">
      <td>ComPughter Ratings</td>
      <td>176.893</td>
    </tr>
  </tbody>
</table>
<br>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: center;">
      <th>Model</th>
      <th>Binary Straight Up (%)</th>
    </tr>
  </thead>
  <tbody>
    <tr align="center">
      <td>ESPN BPI</td>
      <td>77.80</td>
    </tr>
    <tr align="center">
      <td>Line</td>
      <td>77.75</td>
    </tr>
    <tr align="center">
      <td>Dokter Entropy</td>
      <td>77.65</td>
    </tr>
    <tr align="center">
      <td>Opening Line</td>
      <td>77.46</td>
    </tr>
    <tr align="center">
      <td>TeamRankings</td>
      <td>77.41</td>
    </tr>
    <tr align="center">
      <td>Erik Forseth</td>
      <td>77.16</td>
    </tr>
    <tr align="center">
      <td>Sagarin Predictor</td>
      <td>76.77</td>
    </tr>
    <tr align="center">
      <td>Sagarin Rating</td>
      <td>76.03</td>
    </tr>
    <tr align="center">
      <td>StatFox</td>
      <td>75.25</td>
    </tr>
    <tr align="center">
      <td>Sagarin Recent</td>
      <td>75.15</td>
    </tr>
    <tr align="center">
      <td>Kenneth Massey</td>
      <td>74.95</td>
    </tr>
    <tr align="center">
      <td>Sagarin Golden Mean</td>
      <td>74.95</td>
    </tr>
    <tr align="center">
      <td>ComPughter Ratings</td>
      <td>74.85</td>
    </tr>
    <tr align="center">
      <td>DRatings.com</td>
      <td>74.71</td>
    </tr>
    <tr align="center">
      <td>Sonny Moore</td>
      <td>74.36</td>
    </tr>
  </tbody>
</table>
<br><br>
Clearly the line is the best statistical predictor of the outcome. Nevertheless, we can ask how each model would have done against the spread, shown below: 
<br>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: center;">
      <th>Model</th>
      <th>Against the Spread (%)</th>
    </tr>
  </thead>
  <tbody>
    <tr align="center">
      <td>Opening Line</td>
      <td>52.80</td>
    </tr>
    <tr align="center">
      <td>DRatings.com</td>
      <td>52.36</td>
    </tr>
    <tr align="center">
      <td>Erik Forseth</td>
      <td>51.82</td>
    </tr>
    <tr align="center">
      <td>ComPughter Ratings</td>
      <td>51.38</td>
    </tr>
    <tr align="center">
      <td>ESPN BPI</td>
      <td>51.03</td>
    </tr>
    <tr align="center">
      <td>Dokter Entropy</td>
      <td>50.49</td>
    </tr>
    <tr align="center">
      <td>Sonny Moore</td>
      <td>50.39</td>
    </tr>
    <tr align="center">
      <td>Sagarin Golden Mean</td>
      <td>49.95</td>
    </tr>
    <tr align="center">
      <td>TeamRankings</td>
      <td>49.56</td>
    </tr>
    <tr align="center">
      <td>StatFox</td>
      <td>49.56</td>
    </tr>
    <tr align="center">
      <td>Sagarin Rating</td>
      <td>48.97</td>
    </tr>
    <tr align="center">
      <td>Sagarin Predictor</td>
      <td>48.97</td>
    </tr>
    <tr align="center">
      <td>Kenneth Massey</td>
      <td>48.82</td>
    </tr>
    <tr align="center">
      <td>Sagarin Recent</td>
      <td>48.72</td>
    </tr>
  </tbody>
</table>
<br><br>
 Although no individual model predicts the point spread as well as the line, we might ask whether any linear combination of models can do so. Let's regress the observed margins of victory onto the predictions of each model, but constrain the regression to have nonnegative coefficients. This would give the optimal (backward-looking) mixture of predictors. We find: 
<br>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: center;">
      <th>Model</th>
      <th>Coefficient</th>
    </tr>
  </thead>
  <tbody>
    <tr align="center">
      <td>Opening Line</td>
      <td>0.417</td>
    </tr>
    <tr align="center">
      <td>ESPN BPI</td>
      <td>0.308</td>
    </tr>
    <tr align="center">
      <td>Erik Forseth</td>
      <td>0.245</td>
    </tr>
    <tr align="center">
      <td>Dokter Entropy</td>
      <td>0.064</td>
    </tr>
    <tr align="center">
      <td>Kenneth Massey</td>
      <td>0.000</td>
    </tr>
    <tr align="center">
      <td>Sagarin Rating</td>
      <td>0.000</td>
    </tr>
    <tr align="center">
      <td>Sonny Moore</td>
      <td>0.000</td>
    </tr>
    <tr align="center">
      <td>TeamRankings</td>
      <td>0.000</td>
    </tr>
    <tr align="center">
      <td>StatFox</td>
      <td>0.000</td>
    </tr>
    <tr align="center">
      <td>Sagarin Recent</td>
      <td>0.000</td>
    </tr>
    <tr align="center">
      <td>Sagarin Predictor</td>
      <td>0.000</td>
    </tr>
    <tr align="center">
      <td>Sagarin Golden Mean</td>
      <td>0.000</td>
    </tr>
    <tr align="center">
      <td>DRatings.com</td>
      <td>0.000</td>
    </tr>
    <tr align="center">
      <td>ComPughter Ratings</td>
      <td>0.000</td>
    </tr>
  </tbody>
</table> 
<br>
The MSE of this hypothetical predictor would be 142.915. Note that this is optimistic, since in addition to being backward-looking, we both fit the model and then computed the MSE using the full dataset. 
<br><br>
Out of curiosity, what if we included the line itself in the above regression? Can any of our models add value when combined with the line?<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: center;">
      <th>Model</th>
      <th>Coefficient</th>
    </tr>
  </thead>
  <tbody>
    <tr align="center">
      <td>Opening Line</td>
      <td>0.320</td>
    </tr>
    <tr align="center">
      <td>ESPN BPI</td>
      <td>0.306</td>
    </tr>
    <tr align="center">
      <td>Erik Forseth</td>
      <td>0.206</td>
    </tr>
    <tr align="center">
      <td>Line</td>
      <td>0.149</td>
    </tr>
    <tr align="center">
      <td>Dokter Entropy</td>
      <td>0.053</td>
    </tr>
    <tr align="center">
      <td>Kenneth Massey</td>
      <td>0.000</td>
    </tr>
    <tr align="center">
      <td>Sagarin Rating</td>
      <td>0.000</td>
    </tr>
    <tr align="center">
      <td>Sonny Moore</td>
      <td>0.000</td>
    </tr>
    <tr align="center">
      <td>TeamRankings</td>
      <td>0.000</td>
    </tr>
    <tr align="center">
      <td>StatFox</td>
      <td>0.000</td>
    </tr>
    <tr align="center">
      <td>Sagarin Recent</td>
      <td>0.000</td>
    </tr>
    <tr align="center">
      <td>Sagarin Predictor</td>
      <td>0.000</td>
    </tr>
    <tr align="center">
      <td>Sagarin Golden Mean</td>
      <td>0.000</td>
    </tr>
    <tr align="center">
      <td>DRatings.com</td>
      <td>0.000</td>
    </tr>
    <tr align="center">
      <td>ComPughter Ratings</td>
      <td>0.000</td>
    </tr>
  </tbody>
</table> 
<br>
It seems that a few of the models are able to add some value to the line. The hypothetical MSE of this mixture would be 142.881.
