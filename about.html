---
layout: default
title: About this model.
---
A large number of people have developed models for predicting the outcomes of college basketball games. For those that have made their picks publicly available, <a href="http://www.thepredictiontracker.com/basketball.php">ThePredictionTracker</a> does a great service by tracking the live performance of each model over the course of the season. Unfortunately, it's difficult to do a direct comparison of models using the summary page on the Tracker, in part because each model has predicted a different subset of games (in many cases this is accidental -- schedules get modified and web scrapers don't pick up the changes -- but some models don't start making picks altogether until weeks or months into the season). Throughout the season, I'll try to update this page with some further analysis of the Tracker data. For what follows, I chose a subset of models which have made picks since the very beginning of the season, and I threw out games for which any of those models did not make a pick. In a (somewhat lazy) attempt to address misprinted lines, I filtered out any games for which the opening and closing lines differed by more than 5 points (it's very rare that this really happens). 
<br><br>
Results are shown as of 2019-12-08 for a set of 814 games: 
<br>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: center;">
      <th>Model</th>
      <th>Mean Squared Error (MSE)</th>
    </tr>
  </thead>
  <tbody>
    <tr align="center">
      <td>Opening Line</td>
      <td>140.405</td>
    </tr>
    <tr align="center">
      <td>Line</td>
      <td>140.750</td>
    </tr>
    <tr align="center">
      <td>Erik Forseth</td>
      <td>142.621</td>
    </tr>
    <tr align="center">
      <td>TeamRankings</td>
      <td>143.807</td>
    </tr>
    <tr align="center">
      <td>ESPN BPI</td>
      <td>146.133</td>
    </tr>
    <tr align="center">
      <td>Sagarin Predictor</td>
      <td>146.624</td>
    </tr>
    <tr align="center">
      <td>Dokter Entropy</td>
      <td>147.576</td>
    </tr>
    <tr align="center">
      <td>Sagarin Rating</td>
      <td>148.024</td>
    </tr>
    <tr align="center">
      <td>Sagarin Golden Mean</td>
      <td>148.134</td>
    </tr>
    <tr align="center">
      <td>Sagarin Recent</td>
      <td>158.560</td>
    </tr>
    <tr align="center">
      <td>StatFox</td>
      <td>158.711</td>
    </tr>
    <tr align="center">
      <td>DRatings.com</td>
      <td>158.886</td>
    </tr>
    <tr align="center">
      <td>Sonny Moore</td>
      <td>159.271</td>
    </tr>
    <tr align="center">
      <td>Kenneth Massey</td>
      <td>160.440</td>
    </tr>
    <tr align="center">
      <td>ComPughter Ratings</td>
      <td>175.863</td>
    </tr>
  </tbody>
</table>
<br>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: center;">
      <th>Model</th>
      <th>Binary Straight Up (%)</th>
    </tr>
  </thead>
  <tbody>
    <tr align="center">
      <td>Dokter Entropy</td>
      <td>77.58</td>
    </tr>
    <tr align="center">
      <td>Line</td>
      <td>77.33</td>
    </tr>
    <tr align="center">
      <td>ESPN BPI</td>
      <td>77.27</td>
    </tr>
    <tr align="center">
      <td>TeamRankings</td>
      <td>77.27</td>
    </tr>
    <tr align="center">
      <td>Opening Line</td>
      <td>77.09</td>
    </tr>
    <tr align="center">
      <td>Sagarin Predictor</td>
      <td>76.84</td>
    </tr>
    <tr align="center">
      <td>Erik Forseth</td>
      <td>76.47</td>
    </tr>
    <tr align="center">
      <td>Sagarin Rating</td>
      <td>75.68</td>
    </tr>
    <tr align="center">
      <td>Sagarin Golden Mean</td>
      <td>74.82</td>
    </tr>
    <tr align="center">
      <td>Sagarin Recent</td>
      <td>74.63</td>
    </tr>
    <tr align="center">
      <td>Kenneth Massey</td>
      <td>74.08</td>
    </tr>
    <tr align="center">
      <td>DRatings.com</td>
      <td>74.08</td>
    </tr>
    <tr align="center">
      <td>Sonny Moore</td>
      <td>73.96</td>
    </tr>
    <tr align="center">
      <td>StatFox</td>
      <td>73.83</td>
    </tr>
    <tr align="center">
      <td>ComPughter Ratings</td>
      <td>73.71</td>
    </tr>
  </tbody>
</table>
<br><br>
Clearly the line is the best statistical predictor of the outcome. Nevertheless, we can ask how each model would have done against the spread, shown below: 
<br>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: center;">
      <th>Model</th>
      <th>Against the Spread (%)</th>
    </tr>
  </thead>
  <tbody>
    <tr align="center">
      <td>DRatings.com</td>
      <td>53.07</td>
    </tr>
    <tr align="center">
      <td>Opening Line</td>
      <td>52.40</td>
    </tr>
    <tr align="center">
      <td>Erik Forseth</td>
      <td>51.04</td>
    </tr>
    <tr align="center">
      <td>ComPughter Ratings</td>
      <td>51.04</td>
    </tr>
    <tr align="center">
      <td>Sonny Moore</td>
      <td>50.06</td>
    </tr>
    <tr align="center">
      <td>ESPN BPI</td>
      <td>49.88</td>
    </tr>
    <tr align="center">
      <td>Sagarin Golden Mean</td>
      <td>49.75</td>
    </tr>
    <tr align="center">
      <td>TeamRankings</td>
      <td>49.32</td>
    </tr>
    <tr align="center">
      <td>Dokter Entropy</td>
      <td>49.26</td>
    </tr>
    <tr align="center">
      <td>Sagarin Recent</td>
      <td>49.14</td>
    </tr>
    <tr align="center">
      <td>Kenneth Massey</td>
      <td>48.22</td>
    </tr>
    <tr align="center">
      <td>Sagarin Rating</td>
      <td>48.10</td>
    </tr>
    <tr align="center">
      <td>Sagarin Predictor</td>
      <td>47.97</td>
    </tr>
    <tr align="center">
      <td>StatFox</td>
      <td>47.60</td>
    </tr>
  </tbody>
</table>
<br><br>
 Although no individual model predicts the point spread as well as the line, we might ask whether any linear combination of models can do so. Let's regress the observed margins of victory onto the predictions of each model, but constrain the regression to have nonnegative coefficients. This would give the optimal (backward-looking) mixture of predictors. We find: 
<br>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: center;">
      <th>Model</th>
      <th>Coefficient</th>
    </tr>
  </thead>
  <tbody>
    <tr align="center">
      <td>Opening Line</td>
      <td>0.604</td>
    </tr>
    <tr align="center">
      <td>ESPN BPI</td>
      <td>0.253</td>
    </tr>
    <tr align="center">
      <td>Erik Forseth</td>
      <td>0.128</td>
    </tr>
    <tr align="center">
      <td>Dokter Entropy</td>
      <td>0.032</td>
    </tr>
    <tr align="center">
      <td>ComPughter Ratings</td>
      <td>0.008</td>
    </tr>
    <tr align="center">
      <td>Kenneth Massey</td>
      <td>0.000</td>
    </tr>
    <tr align="center">
      <td>Sagarin Rating</td>
      <td>0.000</td>
    </tr>
    <tr align="center">
      <td>Sonny Moore</td>
      <td>0.000</td>
    </tr>
    <tr align="center">
      <td>TeamRankings</td>
      <td>0.000</td>
    </tr>
    <tr align="center">
      <td>StatFox</td>
      <td>0.000</td>
    </tr>
    <tr align="center">
      <td>Sagarin Recent</td>
      <td>0.000</td>
    </tr>
    <tr align="center">
      <td>Sagarin Predictor</td>
      <td>0.000</td>
    </tr>
    <tr align="center">
      <td>Sagarin Golden Mean</td>
      <td>0.000</td>
    </tr>
    <tr align="center">
      <td>DRatings.com</td>
      <td>0.000</td>
    </tr>
  </tbody>
</table> 
<br>
The MSE of this hypothetical predictor would be 139.805. Note that this is optimistic, since in addition to being backward-looking, we both fit the model and then computed the MSE using the full dataset. 
<br><br>
Out of curiosity, what if we included the line itself in the above regression? Can any of our models add value when combined with the line?<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: center;">
      <th>Model</th>
      <th>Coefficient</th>
    </tr>
  </thead>
  <tbody>
    <tr align="center">
      <td>Opening Line</td>
      <td>0.377</td>
    </tr>
    <tr align="center">
      <td>Line</td>
      <td>0.341</td>
    </tr>
    <tr align="center">
      <td>ESPN BPI</td>
      <td>0.241</td>
    </tr>
    <tr align="center">
      <td>Erik Forseth</td>
      <td>0.059</td>
    </tr>
    <tr align="center">
      <td>Dokter Entropy</td>
      <td>0.003</td>
    </tr>
    <tr align="center">
      <td>Kenneth Massey</td>
      <td>0.000</td>
    </tr>
    <tr align="center">
      <td>Sagarin Rating</td>
      <td>0.000</td>
    </tr>
    <tr align="center">
      <td>Sonny Moore</td>
      <td>0.000</td>
    </tr>
    <tr align="center">
      <td>TeamRankings</td>
      <td>0.000</td>
    </tr>
    <tr align="center">
      <td>StatFox</td>
      <td>0.000</td>
    </tr>
    <tr align="center">
      <td>Sagarin Recent</td>
      <td>0.000</td>
    </tr>
    <tr align="center">
      <td>Sagarin Predictor</td>
      <td>0.000</td>
    </tr>
    <tr align="center">
      <td>Sagarin Golden Mean</td>
      <td>0.000</td>
    </tr>
    <tr align="center">
      <td>DRatings.com</td>
      <td>0.000</td>
    </tr>
    <tr align="center">
      <td>ComPughter Ratings</td>
      <td>0.000</td>
    </tr>
  </tbody>
</table> 
<br>
It seems that a few of the models are able to add some value to the line. The hypothetical MSE of this mixture would be 139.629.
